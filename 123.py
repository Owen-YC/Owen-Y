import streamlit as st
from google import genai
from google.genai import types
import time

# CSS ìŠ¤íƒ€ì¼ ì •ì˜ (ì œëª©ì—ë§Œ UI/UX íš¨ê³¼)
def load_css():
    st.markdown("""
    <style>
    /* íƒ€ì´í‹€ ìŠ¤íƒ€ì¼ - Gray/White ê·¸ë¼ë°ì´ì…˜ */
    .main-title {
        background: linear-gradient(45deg, #495057, #6c757d, #adb5bd, #6c757d);
        background-size: 400% 400%;
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        font-size: 3rem;
        font-weight: 700;
        text-align: center;
        margin-bottom: 1rem;
        animation: gradientMove 4s ease-in-out infinite, textGlow 2s ease-in-out infinite alternate;
        text-shadow: 0 0 20px rgba(108, 117, 125, 0.3);
        letter-spacing: 1px;
    }
    
    @keyframes gradientMove {
        0%, 100% { background-position: 0% 50%; }
        50% { background-position: 100% 50%; }
    }
    
    @keyframes textGlow {
        0% { filter: brightness(1); }
        100% { filter: brightness(1.1); }
    }
    </style>
    """, unsafe_allow_html=True)

def main():
    # CSS ë¡œë“œ
    load_css()
    
    # --- Streamlit í˜ì´ì§€ ì„¤ì • ---
    st.set_page_config(
        page_title="SCM AI Agent",
        page_icon="ğŸ¤–",
        layout="centered"
    )
    
    # ì œëª© (UI/UX íš¨ê³¼ ì ìš©)
    st.markdown("""
    <h1 class="main-title">SCM AI Agent</h1>
    """, unsafe_allow_html=True)
    st.caption("Google ê²€ìƒ‰ì„ í†µí•´ ìµœì‹  ì •ë³´ë¥¼ ë°˜ì˜í•˜ì—¬ SCM ë¦¬ìŠ¤í¬ ì‹œë‚˜ë¦¬ì˜¤ ì „ëµì„ ì œì•ˆí•©ë‹ˆë‹¤.")

    # --- API í‚¤ í•˜ë“œì½”ë”© ---
    API_KEY = "AIzaSyCJ1F-HMS4NkQ64f1tDRqJV_N9db0MmKpI"

    # --- ì±—ë´‡ ëŒ€í™” ë‚´ì—­ ì´ˆê¸°í™” ---
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! SCM ë¦¬ìŠ¤í¬ ì „ëµì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”."}
        ]

    # --- ì´ì „ ëŒ€í™” ë‚´ì—­ ì¶œë ¥ ---
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # --- ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ---
    if prompt := st.chat_input("êµ­ê°€, ë¦¬ìŠ¤í¬, ì „ëµ ë“± ê¶ê¸ˆí•œ ì ì„ ì§ˆë¬¸í•˜ì„¸ìš”."):
        # ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ëŒ€í™” ë‚´ì—­ì— ì¶”ê°€í•˜ê³  í™”ë©´ì— í‘œì‹œ
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # --- UI/UX ê°œì„ : ë™ì  ì• ë‹ˆë©”ì´ì…˜ìœ¼ë¡œ ë‹µë³€ ìƒì„± ìƒíƒœ í‘œì‹œ ---
        with st.chat_message("assistant"):
            # ë‹µë³€ì´ ìŠ¤íŠ¸ë¦¬ë°ë  ë¹ˆ ê³µê°„(placeholder)ì„ ë§Œë“­ë‹ˆë‹¤.
            message_placeholder = st.empty()
            # "ìƒì„± ì¤‘"ì„ ë‚˜íƒ€ë‚¼ ì• ë‹ˆë©”ì´ì…˜ í”„ë ˆì„
            animation_frames = ["", " .", " ..", " ..."]
            animation_index = 0
            full_response = ""

            # API í˜¸ì¶œ ì „, ì‚¬ìš©ìì—ê²Œ ì¦‰ê°ì ì¸ í”¼ë“œë°±ì„ ì¤ë‹ˆë‹¤.
            message_placeholder.markdown("ìƒê° ì¤‘...")

            try:
                # --- Gemini API í˜¸ì¶œ ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼) ---
                client = genai.Client(api_key=API_KEY)

                system_instruction = [
                    types.Part.from_text(text="""SCM ë¦¬ìŠ¤í¬ ì‹œë‚˜ë¦¬ì˜¤ ì „ëµì„ ì§œì¤¬ìœ¼ë©´ í•´.
                    ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°ˆ ìˆ˜ ìˆëŠ” ê±¸ë¡œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê²ƒë“¤ì´ ìˆì–´ :
                     - ë°œìƒ êµ­ê°€ì— ëŒ€í•œ ë¦¬ìŠ¤í¬ ì •ë„ë¥¼ íŒŒì•…
                     - ë¦¬ìŠ¤í¬ í—·ì§€(Hedge) ë°©ë²• ì œì•ˆ
                     - ëŒ€ì²´ ì „ëµ ì œì•ˆ
                    ---
                    ë‹µë³€ ì „ì—ëŠ” !!í•­ìƒ!! ìœ ì €ê°€ ì…ë ¥í•œ ë‚´ìš©ê³¼ ê´€ë ¨ëœ ìµœì‹  ì •ë³´ë¥¼ google search toolì„ í†µí•´ ê²€ìƒ‰í•œ ë’¤, í•´ë‹¹ ì •ë³´ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•  ê²ƒ."""),
                ]
                google_search_tool = types.Tool(google_search=types.GoogleSearch())
                safety_settings = [
                    types.SafetySetting(category="HARM_CATEGORY_HARASSMENT", threshold="BLOCK_NONE"),
                    types.SafetySetting(category="HARM_CATEGORY_HATE_SPEECH", threshold="BLOCK_NONE"),
                    types.SafetySetting(category="HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold="BLOCK_NONE"),
                    types.SafetySetting(category="HARM_CATEGORY_DANGEROUS_CONTENT", threshold="BLOCK_NONE"),
                ]
                generate_content_config = types.GenerateContentConfig(
                    thinking_config=types.ThinkingConfig(thinking_budget=0),
                    safety_settings=safety_settings,
                    system_instruction=system_instruction,
                    tools=[google_search_tool]
                )
                contents_for_api = []
                for msg in st.session_state.messages:
                    role = "model" if msg["role"] == "assistant" else "user"
                    contents_for_api.append(
                        types.Content(role=role, parts=[types.Part.from_text(text=msg["content"])])
                    )

                model_name = "gemini-2.5-flash"
                response_stream = client.models.generate_content_stream(
                    model=model_name,
                    contents=contents_for_api,
                    config=generate_content_config,
                )

                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ì²˜ë¦¬í•˜ë©° ë™ì  ì• ë‹ˆë©”ì´ì…˜ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
                for chunk in response_stream:
                    if chunk.text:
                        full_response += chunk.text
                        # í˜„ì¬ê¹Œì§€ì˜ ë‹µë³€ + ì• ë‹ˆë©”ì´ì…˜ í”„ë ˆì„ì„ placeholderì— ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
                        animation_char = animation_frames[animation_index % len(animation_frames)]
                        message_placeholder.markdown(full_response + animation_char)
                        animation_index += 1
                        # ì•„ì£¼ ì§§ì€ ë”œë ˆì´ë¥¼ ì£¼ì–´ ì• ë‹ˆë©”ì´ì…˜ì´ ë³´ì´ë„ë¡ í•©ë‹ˆë‹¤.
                        time.sleep(0.05)
                
                # ë‹µë³€ ìƒì„±ì´ ì™„ë£Œë˜ë©´ ì• ë‹ˆë©”ì´ì…˜ ì—†ì´ ìµœì¢… ê²°ê³¼ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.
                message_placeholder.markdown(full_response)

            except Exception as e:
                # ì—ëŸ¬ ë°œìƒ ì‹œ, placeholderì— ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
                st.error(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                full_response = "ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë™ì•ˆ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                message_placeholder.markdown(full_response)
            
            # ì™„ì„±ëœ ì „ì²´ ì‘ë‹µì„ ëŒ€í™” ë‚´ì—­ì— ì €ì¥í•©ë‹ˆë‹¤.
            st.session_state.messages.append({"role": "assistant", "content": full_response})

if __name__ == "__main__":
    main()
